#!/usr/bin/env python3
"""
Batch Crawler: ãƒãƒƒãƒå‡¦ç†ç›£è¦–ãƒ‡ãƒ¼ãƒ¢ãƒ³

ã€æ©Ÿèƒ½ã€‘
1. è¤‡æ•°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒãƒƒãƒçŠ¶æ…‹ã‚’ç›£è¦–
2. å®Œäº†æ¤œçŸ¥æ™‚ã«å¾Œç¶šãƒ•ã‚§ãƒ¼ã‚ºã‚’è‡ªå‹•å®Ÿè¡Œï¼ˆP2-B â†’ P2.5 â†’ P3ï¼‰
3. çŠ¶æ…‹ç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆbatch_status.jsonï¼‰ã§æ°¸ç¶šåŒ–
4. å¤±æ•—æ™‚ã®ãƒªãƒˆãƒ©ã‚¤ã¨ã‚¨ãƒ©ãƒ¼é€šçŸ¥

ã€ä½¿ã„æ–¹ã€‘
  python batch_crawler.py start    # ãƒ‡ãƒ¼ãƒ¢ãƒ³é–‹å§‹
  python batch_crawler.py status   # ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤º
  python batch_crawler.py add <project_name>  # æ‰‹å‹•ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¿½åŠ 
"""
import os
import sys
import json
import time
import subprocess
from datetime import datetime
from dotenv import load_dotenv

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from openai import OpenAI
from config import BATCH_CHECK_INTERVAL, LOGS_DIR, PROJECT_ROOT
from logger_utils import DualLogger

load_dotenv()

# === è¨­å®š ===
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
BATCH_STATUS_FILE = os.path.join(BASE_DIR, "batch_status.json")
CRAWLER_LOG_FILE = os.path.join(LOGS_DIR, "batch_crawler.log")

# å¾Œç¶šã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‘ã‚¹
P2_BATCH_RETRIEVE_SCRIPT = os.path.join(BASE_DIR, "Batch", "p2_gpt_batch_retrieve.py")
P2_5_VIDEO_SCRIPT = os.path.join(BASE_DIR, "p2_5_hailuo_generate_videos.py")
P3_UPLOAD_SCRIPT = os.path.join(BASE_DIR, "p3_gdrive_upload.py")


def load_batch_status():
    """
    ãƒãƒƒãƒçŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    
    Returns:
        dict: {
            "projects": {
                "project_name": {
                    "batch_id": "batch_xxx",
                    "batch_type": "gpt_images",  # or "claude_prompts"
                    "status": "in_progress",  # validating, in_progress, completed, failed
                    "submitted_at": "2024-01-01T00:00:00",
                    "last_checked": "2024-01-01T00:00:00",
                    "output_dir": "/path/to/output",
                    "model_name": "claude"
                }
            }
        }
    """
    if os.path.exists(BATCH_STATUS_FILE):
        with open(BATCH_STATUS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"projects": {}}


def save_batch_status(status_data):
    """ãƒãƒƒãƒçŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
    with open(BATCH_STATUS_FILE, "w", encoding="utf-8") as f:
        json.dump(status_data, f, ensure_ascii=False, indent=2)


def register_batch(project_name, batch_id, batch_type, output_dir, model_name="claude"):
    """
    æ–°ã—ã„ãƒãƒƒãƒã‚’ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã«ç™»éŒ²
    
    Args:
        project_name: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
        batch_id: OpenAI Batch ID
        batch_type: "gpt_images" or "claude_prompts"
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_name: ãƒ¢ãƒ‡ãƒ«å
    """
    status_data = load_batch_status()
    
    status_data["projects"][project_name] = {
        "batch_id": batch_id,
        "batch_type": batch_type,
        "status": "validating",
        "submitted_at": datetime.now().isoformat(),
        "last_checked": None,
        "output_dir": output_dir,
        "model_name": model_name,
        "retry_count": 0
    }
    
    save_batch_status(status_data)
    print(f"âœ… ãƒãƒƒãƒç™»éŒ²å®Œäº†: {project_name} ({batch_id})")


def unregister_batch(project_name):
    """ãƒãƒƒãƒã‚’ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‹ã‚‰å‰Šé™¤"""
    status_data = load_batch_status()
    
    if project_name in status_data["projects"]:
        del status_data["projects"][project_name]
        save_batch_status(status_data)
        print(f"âœ… ãƒãƒƒãƒå‰Šé™¤: {project_name}")


def check_batch_status_api(batch_id, logger):
    """
    OpenAI API ã§ãƒãƒƒãƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª
    
    Returns:
        tuple: (status, batch_object)
    """
    try:
        client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
        batch = client.batches.retrieve(batch_id)
        
        # é€²æ—æƒ…å ±
        if hasattr(batch, 'request_counts'):
            counts = batch.request_counts
            completed = getattr(counts, 'completed', 0)
            failed = getattr(counts, 'failed', 0)
            total = getattr(counts, 'total', 0)
            logger.log(f"  é€²æ—: {completed}/{total} å®Œäº†, {failed} å¤±æ•—")
        
        return batch.status, batch
    
    except Exception as e:
        logger.log(f"âš ï¸ API ã‚¨ãƒ©ãƒ¼: {e}")
        return "error", None


def update_current_project(project_name, model_name, output_dir):
    """
    _current_project.json ã‚’æ›´æ–°ï¼ˆå¾Œç¶šã‚¹ã‚¯ãƒªãƒ—ãƒˆç”¨ï¼‰
    """
    contact_note_file = os.path.join(BASE_DIR, "_current_project.json")
    
    data = {
        "project_name": project_name,
        "model_name": model_name,
        "script_full_path": "",  # ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§ã¯ä¸è¦
        "start_time": time.time()
    }
    
    with open(contact_note_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def run_script(script_path, phase_name, logger):
    """
    ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
    
    Returns:
        bool: æˆåŠŸæ™‚ True
    """
    if not os.path.exists(script_path):
        logger.log(f"ğŸš¨ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {script_path}")
        return False
    
    logger.log(f"\nâ–¶ï¸ {phase_name} ã‚’å®Ÿè¡Œä¸­...")
    
    try:
        import locale
        system_encoding = locale.getpreferredencoding() or 'utf-8'
        
        result = subprocess.run(
            [sys.executable, script_path],
            capture_output=True,
            text=True,
            encoding=system_encoding,
            errors='replace',
            timeout=86400  # 24æ™‚é–“
        )
        
        if result.returncode == 0:
            logger.log(f"âœ… {phase_name} å®Œäº†")
            return True
        else:
            logger.log(f"âŒ {phase_name} å¤±æ•— (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode})")
            if result.stderr:
                logger.log(f"  ã‚¨ãƒ©ãƒ¼: {result.stderr[:500]}")
            return False
    
    except subprocess.TimeoutExpired:
        logger.log(f"âŒ {phase_name} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return False
    except Exception as e:
        logger.log(f"âŒ {phase_name} ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def execute_post_batch_flow(project_name, batch_type, output_dir, model_name, logger):
    """
    ãƒãƒƒãƒå®Œäº†å¾Œã®ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
    
    P2 (GPT Images) ã®å ´åˆ:
        P2-B Retrieve â†’ P2.5 Videos â†’ P3 Upload
    
    P1 (Claude Prompts) ã®å ´åˆ:
        P1-B Retrieve â†’ P2 Images â†’ ...
    """
    logger.log(f"\n{'='*60}")
    logger.log(f"ğŸš€ å¾Œç¶šãƒ•ãƒ­ãƒ¼é–‹å§‹: {project_name}")
    logger.log(f"{'='*60}")
    
    # _current_project.json ã‚’æ›´æ–°
    update_current_project(project_name, model_name, output_dir)
    
    if batch_type == "gpt_images":
        # P2-B: ãƒãƒƒãƒçµæœå–å¾—
        if not run_script(P2_BATCH_RETRIEVE_SCRIPT, "Phase 2-B (GPT Batch Retrieve)", logger):
            logger.log("âŒ P2-B å¤±æ•—ã€‚ãƒ•ãƒ­ãƒ¼ä¸­æ–­ã€‚")
            return False
        
        # P2.5: å‹•ç”»ç”Ÿæˆ
        if not run_script(P2_5_VIDEO_SCRIPT, "Phase 2.5 (Video Generation)", logger):
            logger.log("âš ï¸ P2.5 å¤±æ•—ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯ç¶šè¡Œã—ã¾ã™ã€‚")
        
        # P3: Google Drive ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if not run_script(P3_UPLOAD_SCRIPT, "Phase 3 (Google Drive Upload)", logger):
            logger.log("âŒ P3 å¤±æ•—ã€‚")
            return False
    
    elif batch_type == "claude_prompts":
        # Claude ãƒãƒƒãƒã®å ´åˆã¯ P1-B â†’ P2 â†’ P2.5 â†’ P3
        # TODO: å®Ÿè£…
        logger.log("âš ï¸ Claude ãƒãƒƒãƒã®å¾Œç¶šãƒ•ãƒ­ãƒ¼ã¯æœªå®Ÿè£…")
        return False
    
    logger.log(f"\n{'='*60}")
    logger.log(f"âœ… å¾Œç¶šãƒ•ãƒ­ãƒ¼å®Œäº†: {project_name}")
    logger.log(f"{'='*60}")
    
    return True


def crawler_loop(logger):
    """
    ãƒ¡ã‚¤ãƒ³ã®ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ãƒ«ãƒ¼ãƒ—
    """
    logger.log(f"\n{'='*60}")
    logger.log(f"ğŸ”„ Batch Crawler é–‹å§‹")
    logger.log(f"   ãƒã‚§ãƒƒã‚¯é–“éš”: {BATCH_CHECK_INTERVAL}ç§’")
    logger.log(f"   çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«: {BATCH_STATUS_FILE}")
    logger.log(f"{'='*60}")
    
    while True:
        try:
            status_data = load_batch_status()
            projects = status_data.get("projects", {})
            
            if not projects:
                logger.log(f"\nâ³ ç›£è¦–å¯¾è±¡ã®ãƒãƒƒãƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚å¾…æ©Ÿä¸­...")
                time.sleep(BATCH_CHECK_INTERVAL)
                continue
            
            logger.log(f"\nğŸ” {len(projects)} ä»¶ã®ãƒãƒƒãƒã‚’ç¢ºèªä¸­...")
            
            completed_projects = []
            
            for project_name, project_info in projects.items():
                batch_id = project_info["batch_id"]
                current_status = project_info["status"]
                
                # æ—¢ã«å®Œäº†/å¤±æ•—ã—ã¦ã„ã‚‹ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—
                if current_status in ["completed", "failed", "expired", "cancelled"]:
                    continue
                
                logger.log(f"\nğŸ“‹ {project_name}: {batch_id}")
                
                # API ã§ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
                api_status, batch_obj = check_batch_status_api(batch_id, logger)
                
                # çŠ¶æ…‹ã‚’æ›´æ–°
                project_info["status"] = api_status
                project_info["last_checked"] = datetime.now().isoformat()
                
                if api_status == "completed":
                    logger.log(f"âœ… ãƒãƒƒãƒå®Œäº†: {project_name}")
                    completed_projects.append(project_name)
                
                elif api_status in ["failed", "expired", "cancelled"]:
                    logger.log(f"âŒ ãƒãƒƒãƒå¤±æ•—: {project_name} ({api_status})")
                    if batch_obj and hasattr(batch_obj, 'errors'):
                        logger.log(f"   ã‚¨ãƒ©ãƒ¼: {batch_obj.errors}")
                
                elif api_status == "error":
                    # API ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—ã‚„ã™
                    project_info["retry_count"] = project_info.get("retry_count", 0) + 1
                    if project_info["retry_count"] >= 5:
                        logger.log(f"âŒ API ã‚¨ãƒ©ãƒ¼ãŒç¶šã„ã¦ã„ã¾ã™: {project_name}")
                
                else:
                    logger.log(f"  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {api_status}")
            
            # çŠ¶æ…‹ã‚’ä¿å­˜
            save_batch_status(status_data)
            
            # å®Œäº†ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å¾Œç¶šãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
            for project_name in completed_projects:
                project_info = projects[project_name]
                
                success = execute_post_batch_flow(
                    project_name,
                    project_info["batch_type"],
                    project_info["output_dir"],
                    project_info["model_name"],
                    logger
                )
                
                if success:
                    # å®Œäº†ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å‰Šé™¤
                    unregister_batch(project_name)
                else:
                    # å¤±æ•—ã—ãŸå ´åˆã¯çŠ¶æ…‹ã‚’æ›´æ–°
                    project_info["status"] = "post_flow_failed"
                    save_batch_status(status_data)
            
            # æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§å¾…æ©Ÿ
            logger.log(f"\nâ³ æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§ {BATCH_CHECK_INTERVAL}ç§’å¾…æ©Ÿ...")
            time.sleep(BATCH_CHECK_INTERVAL)
        
        except KeyboardInterrupt:
            logger.log("\n\nğŸ›‘ Crawler åœæ­¢ï¼ˆCtrl+Cï¼‰")
            break
        
        except Exception as e:
            logger.log(f"\nğŸš¨ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.log(traceback.format_exc())
            time.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ


def show_status():
    """ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤º"""
    status_data = load_batch_status()
    projects = status_data.get("projects", {})
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Batch Crawler Status")
    print(f"{'='*60}")
    
    if not projects:
        print("  ç›£è¦–å¯¾è±¡ã®ãƒãƒƒãƒã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        for project_name, info in projects.items():
            print(f"\nğŸ“‹ {project_name}")
            print(f"   Batch ID: {info['batch_id']}")
            print(f"   Type: {info['batch_type']}")
            print(f"   Status: {info['status']}")
            print(f"   Submitted: {info['submitted_at']}")
            print(f"   Last Checked: {info.get('last_checked', 'Never')}")
    
    print(f"\n{'='*60}")


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹:")
        print("  python batch_crawler.py start   # ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼é–‹å§‹")
        print("  python batch_crawler.py status  # çŠ¶æ…‹è¡¨ç¤º")
        print("  python batch_crawler.py add <project_name> <batch_id> <batch_type> <output_dir>")
        sys.exit(1)
    
    command = sys.argv[1].lower()
    
    if command == "start":
        os.makedirs(LOGS_DIR, exist_ok=True)
        logger = DualLogger(CRAWLER_LOG_FILE)
        crawler_loop(logger)
    
    elif command == "status":
        show_status()
    
    elif command == "add":
        if len(sys.argv) < 6:
            print("ä½¿ã„æ–¹: python batch_crawler.py add <project_name> <batch_id> <batch_type> <output_dir>")
            sys.exit(1)
        
        project_name = sys.argv[2]
        batch_id = sys.argv[3]
        batch_type = sys.argv[4]
        output_dir = sys.argv[5]
        
        register_batch(project_name, batch_id, batch_type, output_dir)
    
    elif command == "remove":
        if len(sys.argv) < 3:
            print("ä½¿ã„æ–¹: python batch_crawler.py remove <project_name>")
            sys.exit(1)
        
        project_name = sys.argv[2]
        unregister_batch(project_name)
    
    else:
        print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
        sys.exit(1)


if __name__ == "__main__":
    main()
