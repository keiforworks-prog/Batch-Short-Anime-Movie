#!/usr/bin/env python3
"""
Batch Post-flow Job: ãƒãƒƒãƒå®Œäº†å¾Œã®å‡¦ç†ã‚’å®Ÿè¡Œ

ã€æ©Ÿèƒ½ã€‘
1. ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’å–å¾—
2. P2-B (Batch Retrieve) â†’ P2.5 (Video Generation) â†’ P3 (Upload) ã‚’å®Ÿè¡Œ
3. å®Œäº†å¾Œã« batch_status.json ã‚’æ›´æ–°

ã€èµ·å‹•æ–¹æ³•ã€‘
Checker Job ã‹ã‚‰ Cloud Run Job ã¨ã—ã¦èµ·å‹•ã•ã‚Œã‚‹
ç’°å¢ƒå¤‰æ•°:
  - TARGET_PROJECT_NAME: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
  - TARGET_BATCH_TYPE: ãƒãƒƒãƒã‚¿ã‚¤ãƒ— (gpt_images / claude_prompts)
  - TARGET_OUTPUT_DIR: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
  - TARGET_MODEL_NAME: ãƒ¢ãƒ‡ãƒ«å
"""
import os
import sys
import json
import subprocess
from datetime import datetime
from dotenv import load_dotenv

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from google.cloud import storage

load_dotenv()

# === è¨­å®š ===
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
GCS_BUCKET = os.environ.get("GCS_BUCKET_NAME", "")
BATCH_STATUS_BLOB = "batch_status.json"

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‘ã‚¹
P2_BATCH_RETRIEVE_SCRIPT = os.path.join(BASE_DIR, "Batch", "p2_gpt_batch_retrieve.py")
P2_5_VIDEO_SCRIPT = os.path.join(BASE_DIR, "p2_5_hailuo_generate_videos.py")
P3_UPLOAD_SCRIPT = os.path.join(BASE_DIR, "p3_gdrive_upload.py")
CONTACT_NOTE_FILE = os.path.join(BASE_DIR, "_current_project.json")


def update_current_project(project_name, model_name, output_dir):
    """
    _current_project.json ã‚’æ›´æ–°ï¼ˆå¾Œç¶šã‚¹ã‚¯ãƒªãƒ—ãƒˆç”¨ï¼‰
    """
    import time
    
    data = {
        "project_name": project_name,
        "model_name": model_name,
        "script_full_path": "",
        "start_time": time.time()
    }
    
    with open(CONTACT_NOTE_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ _current_project.json ã‚’æ›´æ–°ã—ã¾ã—ãŸ")


def run_script(script_path, phase_name):
    """
    ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
    """
    if not os.path.exists(script_path):
        print(f"ğŸš¨ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {script_path}")
        return False
    
    print(f"\n{'='*50}")
    print(f"â–¶ï¸ {phase_name} ã‚’å®Ÿè¡Œä¸­...")
    print(f"{'='*50}")
    
    try:
        result = subprocess.run(
            [sys.executable, script_path],
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=86400  # 24æ™‚é–“
        )
        
        # å‡ºåŠ›ã‚’è¡¨ç¤º
        if result.stdout:
            print(result.stdout)
        
        if result.returncode == 0:
            print(f"âœ… {phase_name} å®Œäº†")
            return True
        else:
            print(f"âŒ {phase_name} å¤±æ•— (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode})")
            if result.stderr:
                print(f"ã‚¨ãƒ©ãƒ¼: {result.stderr[:1000]}")
            return False
    
    except subprocess.TimeoutExpired:
        print(f"âŒ {phase_name} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return False
    except Exception as e:
        print(f"âŒ {phase_name} ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def update_batch_status_in_gcs(project_name, new_status):
    """
    GCS ã® batch_status.json ã‚’æ›´æ–°
    """
    if not GCS_BUCKET:
        return
    
    try:
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET)
        blob = bucket.blob(BATCH_STATUS_BLOB)
        
        if not blob.exists():
            return
        
        content = blob.download_as_text()
        status_data = json.loads(content)
        
        if project_name in status_data.get("projects", {}):
            status_data["projects"][project_name]["status"] = new_status
            status_data["projects"][project_name]["completed_at"] = datetime.now().isoformat()
            
            blob.upload_from_string(
                json.dumps(status_data, ensure_ascii=False, indent=2),
                content_type="application/json"
            )
            print(f"âœ… batch_status.json ã‚’æ›´æ–°ã—ã¾ã—ãŸ: {project_name} â†’ {new_status}")
    
    except Exception as e:
        print(f"âš ï¸ batch_status.json ã®æ›´æ–°ã«å¤±æ•—: {e}")


def remove_from_batch_status(project_name):
    """
    GCS ã® batch_status.json ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å‰Šé™¤
    """
    if not GCS_BUCKET:
        return
    
    try:
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET)
        blob = bucket.blob(BATCH_STATUS_BLOB)
        
        if not blob.exists():
            return
        
        content = blob.download_as_text()
        status_data = json.loads(content)
        
        if project_name in status_data.get("projects", {}):
            del status_data["projects"][project_name]
            
            blob.upload_from_string(
                json.dumps(status_data, ensure_ascii=False, indent=2),
                content_type="application/json"
            )
            print(f"âœ… {project_name} ã‚’ batch_status.json ã‹ã‚‰å‰Šé™¤ã—ã¾ã—ãŸ")
    
    except Exception as e:
        print(f"âš ï¸ batch_status.json ã‹ã‚‰ã®å‰Šé™¤ã«å¤±æ•—: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’å–å¾—
    project_name = os.environ.get("TARGET_PROJECT_NAME")
    batch_type = os.environ.get("TARGET_BATCH_TYPE")
    output_dir = os.environ.get("TARGET_OUTPUT_DIR")
    model_name = os.environ.get("TARGET_MODEL_NAME", "claude")
    
    if not project_name:
        print("ğŸš¨ TARGET_PROJECT_NAME ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ Post-flow Job é–‹å§‹")
    print(f"   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_name}")
    print(f"   ãƒãƒƒãƒã‚¿ã‚¤ãƒ—: {batch_type}")
    print(f"   å‡ºåŠ›å…ˆ: {output_dir}")
    print(f"   æ™‚åˆ»: {datetime.now().isoformat()}")
    print(f"{'='*60}")
    
    # _current_project.json ã‚’æ›´æ–°
    update_current_project(project_name, model_name, output_dir)
    
    success = True
    
    if batch_type == "gpt_images":
        # P2-B: ãƒãƒƒãƒçµæœå–å¾—
        if not run_script(P2_BATCH_RETRIEVE_SCRIPT, "Phase 2-B (GPT Batch Retrieve)"):
            print("âŒ P2-B å¤±æ•—")
            update_batch_status_in_gcs(project_name, "post_flow_failed")
            sys.exit(1)
        
        # P2.5: å‹•ç”»ç”Ÿæˆ
        if not run_script(P2_5_VIDEO_SCRIPT, "Phase 2.5 (Video Generation)"):
            print("âš ï¸ P2.5 å¤±æ•—ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯ç¶šè¡Œï¼‰")
            # P2.5 ã®å¤±æ•—ã¯è‡´å‘½çš„ã§ã¯ãªã„
        
        # P3: Google Drive ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if not run_script(P3_UPLOAD_SCRIPT, "Phase 3 (Google Drive Upload)"):
            print("âŒ P3 å¤±æ•—")
            update_batch_status_in_gcs(project_name, "post_flow_failed")
            sys.exit(1)
    
    elif batch_type == "claude_prompts":
        # TODO: Claude ãƒãƒƒãƒã®å¾Œç¶šãƒ•ãƒ­ãƒ¼
        print("âš ï¸ Claude ãƒãƒƒãƒã®å¾Œç¶šãƒ•ãƒ­ãƒ¼ã¯æœªå®Ÿè£…")
        update_batch_status_in_gcs(project_name, "post_flow_failed")
        sys.exit(1)
    
    else:
        print(f"ğŸš¨ ä¸æ˜ãªãƒãƒƒãƒã‚¿ã‚¤ãƒ—: {batch_type}")
        sys.exit(1)
    
    # æˆåŠŸã—ãŸã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å‰Šé™¤
    remove_from_batch_status(project_name)
    
    print(f"\n{'='*60}")
    print(f"ğŸ‰ Post-flow Job å®Œäº†: {project_name}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
